---
title: "Intro"
author: "Hosik Choi"
date: '2019년 6월 25일'
output: html_document
---

```{r eval=FALSE}
x <- c(12, 3, 6, 14, 10)
str(x)num [1:5] 12 3 6 14 10
dim(as.array(x))
```

```{r eval=FALSE}
x <- array(rep(0, 2*3*2), dim=c(2,3,2))
str(x)
dim(x)
```

```{r eval=FALSE}
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
dim(train_images)

typeof(train_images)
digit <- train_images[5, , ]
plot(as.raster(digit, max = 255)) 
```

## 텐서슬라이싱(tensor slicing)
```{r eval=FALSE}
slice <- train_images[10:99, , ]
dim(slice) 
plot(as.raster(slice[1,,], max = 255))
#오른쪽하단이미지추출
slice <- train_images[10:99, 15:28, 15:28]
dim(slice)
plot(as.raster(slice[1,,], max = 255))
```

## 텐서 모양 변경(tensor reshaping)
```{r eval=FALSE}
train_images <- array_reshape(train_images, c(60000, 28*28))
x <- matrix(c(0,1,
              2,3,
              4,5), nrow=3, ncol=2, byrow=TRUE)
x <- array_reshape(x, dim=c(6,1))
x <- array_reshape(x, dim=c(2,3))
dim(t(x)) # 전치(transpose)
```

## 계층 호환성(layer compatibility)
+ 특정 모양의 입력텐서, 지정된  출력 텐서 
+ 입력: 2D 텐서, 첫번째 차원이 784
+ 출력: 차원이 32인 텐서를 반환 
```{r eval=FALSE}
layer <- layer_dense(units=32, input_shape=c(784))
```

# 1-1. 연습

## 훈련자료/평가자료 준비

```{r eval=FALSE}
train_images <- array_reshape(train_images, c(60000, 28*28))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28*28))
test_images <- test_images / 255

train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)
```

## 망 구성

```{r eval=FALSE}
network <- keras_model_sequential() %>% 
  layer_dense(units=512, activation='relu', input_shape = c(28*28)) %>% 
  layer_dense(units=10, activation='softmax')

### 망 컴파일 1
network %>% compile(
  optimizer = 'rmsprop',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy'))

### 망 구성 및 컴파일 2
compile(
  network,
  optimizer = 'rmsprop',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy'))
```

## 모형 적합과 평가

### 모형 적합

```{r eval=FALSE}
network %>% fit(train_images, train_labels, epochs=5, batch_size=128)
```

### 모형 평가

```{r eval=FALSE}
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
```


# 1-2. 실습1: 이진분류

+ **IMDB** 영화감상평: 긍정 1, 부정 0

```{r eval=FALSE}
library(keras)
```

```{r eval=FALSE}
imdb <- dataset_imdb(num_words = 10000) # 출현빈도 기준 상위 1만개

#reuters <- dataset_reuters(num_words=10000)
c(c(tr_data, tr_labels), c(te_data, te_labels)) %<-% imdb
str(tr_data[[1]])
tr_labels[[1]]
max(sapply(tr_data, max))
```

+ 실행에 error가 날 경우
+ Error in py_call_impl(callable, dots$args, dots$keywords) : 
  ValueError: Object arrays cannot be loaded when #allow_pickle=False
https://github.com/rstudio/keras/issues/765

```{r eval=FALSE}
library(tensorflow)
install_tensorflow(version="nightly")
```

## 자료 준비

+ one hot coding

```{r eval=FALSE}
vectorize_sequence <- function(seqs, dims=1e4){
  results <- matrix(0, nrow=length(seqs), ncol=dims)
  for(i in 1:length(seqs)){
    # 특정 index들을 1로 설정 
    results[i, seqs[[i]]] <- 1
  }
  return(results)
}
```

```{r eval=FALSE}
x_tr <- vectorize_sequence(tr_data)
x_te <- vectorize_sequence(te_data)
str(x_tr[1,])
y_tr <- as.numeric(tr_labels)
y_te <- as.numeric(te_labels)
```

## 모형설정

```{r eval=FALSE}
library(keras)
model <- keras_model_sequential() %>%
  layer_dense(units=16, activation="relu", input_shape=10000) %>% 
  layer_dense(units=16, activation="relu") %>%
  layer_dense(units=1, activation="sigmoid")

###{모형컴파일1}

model %>% compile(
  optimizer="rmsprop",
  loss="binary_crossentropy",
  metrics=c("accuracy"))

model %>% compile(
  optimizer=optimizer_rmsprop(lr=0.001),
  loss="binary_crossentropy",
  metrics=c("accuracy"))

###검증집합 설정
val_idx <- 1:1e4
x_val <- x_tr[val_idx,]
partial_x_tr <- x_tr[-val_idx,]
y_val <- y_tr[val_idx]
partial_y_tr <- y_tr[-val_idx]
```
                
## 모델 훈련
                
+ 미니배치(mini-batch, 512개의 표본)을 20번 반복 $\longrightarrow$ 20 epoch
                
```{r eval=FALSE}
model %>% compile(
  optimizer="rmsprop",
  loss="binary_crossentropy",
  metrics=c("accuracy"))

history <- model %>% fit(
  partial_x_tr, partial_y_tr,
  epochs=20, batch_size=512,
  validation_data=list(x_val, y_val))
str(history)
                
plot(history)

history_df <- as.data.frame(history)
str(history_df)
```

## 재훈련

```{r eval=FALSE}
model %>% fit(x_tr, y_tr, epochs=4, batch_size=512)
results <- model %>% evaluate(x_te, y_te)
results
```

## 평가성능 측정

```{r eval=FALSE}
model %>% predict(x_te[1:10,])
```

# 1-3. 실습2: 회귀분석(보스턴 집값 자료)

```{r eval=FALSE}
library(keras)
d <- dataset_boston_housing() # class(d); names(d)
c(c(tr_data, tr_targets), c(te_data, te_targets)) %<-% d
str(tr_data)
str(te_data)
str(tr_targets)
```

## 데이터 표준화(정규화)

```{r eval=FALSE}
m <- apply(tr_data, 2, mean)
s <- apply(tr_data, 2, sd)
tr_data <- scale(tr_data, m, s)
te_data <- scale(te_data, m, s)
```

## 망 구축

```{r eval=FALSE}
build_model <- function(){
  model <- keras_model_sequential() %>%
    layer_dense(units=64, activation="relu",
                input_shape=ncol(tr_data)) %>% 
    layer_dense(units=64, activation="relu") %>%
    layer_dense(units=1)
  model %>% compile(
    optimizer="rmsprop",
    loss="mse",
    metrics=c("mae")
  )
}
```


## k-fold cross-validation

```{r eval=FALSE}
k <- 4
indices <- sample(1:nrow(tr_data))
folds <- cut(1:length(indices), breaks = k, labels = FALSE) 
num_epochs <- 500
all_mae_histories <- NULL
for (i in 1:k) {
  cat("processing fold #", i, "\n")
  
  # 검증자료
  val_indices <- which(folds == i, arr.ind = TRUE)
  val_data <- tr_data[val_indices,]
  val_targets <- tr_targets[val_indices]
  
  # 훈련자료
  partial_tr_data <- tr_data[-val_indices,]
  partial_tr_targets <- tr_targets[-val_indices]
  
  # 모형 생성
  model <- build_model()
  
  # 모형 적합  
  history <- model %>% fit(
    partial_tr_data, partial_tr_targets,
    validation_data = list(val_data, val_targets),
    epochs = num_epochs, batch_size = 1, verbose = 0
  )
  mae_history <- history$metrics$val_mean_absolute_error
  all_mae_histories <- rbind(all_mae_histories, mae_history)
} 
```

+ epoch마다 mae값 저장 

```{r eval=FALSE}
average_mae_history <- data.frame(
  epoch = seq(1:ncol(all_mae_histories)),
  validation_mae = apply(all_mae_histories, 2, mean)
)
```


```{r eval=FALSE}
library(ggplot2)
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_line()
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_smooth()
```

+ 전체자료를 활용한 최종 모형 적합 

```{r eval=FALSE}
model <- build_model()
model %>% fit(train_data, train_targets,
          epochs = 80, batch_size = 16, verbose = 0)
result <- model %>% evaluate(test_data, test_targets)
result
```
